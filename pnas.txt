1、相关背景
2、问题是什么？
3、现有解决方案
4、作者的核心思想、创新点是在哪里
5、通过什么样的实验进行验证
6、对你的启发


全文摘要:
提出可以学习CNN结构的方法，比基于强化学习和进化算法的方法高效。使用了基于序列模型的优化策略(SMBO)，同时学习代理模型引导结构空间的搜索。该方法比基于强化学习的方法效率提高5倍，总计算速度快8倍。这个方法在CIFAR-10和ImageNet获得最高分类精度。

问题：
有许多自动学习神经网络架构的方法，现在的技术一般分为两类，基于进化算法和基于强化学习，这两个方法学习到的神经网络的性能已经优于人工设计的神经网络，但它们需要大量的计算资源。

优点：
1.简单的结构训练更快，可以更快地得到一些初始的结果训练代理模型；
2.代理模型只预测与它所见过的不同的结构的性能；
3.我们将搜索空间分成更小的部分，允许搜索包含更多块的模型。

提出：
搜索空间：
一个cell表示为一个元组，（I1，I2，O1，O2，C）
I1，I2表示输出块，O1，O2表示对输入进行的操作，C是把O1，O2产生的结果整合成为该块的输出。
其中输入包括：该cell中所有之前的块的集合；前一个cell的输出H(c-1，b)；前一个的前一个cell的输出H(c-2，b)。
操作O包含：3*3卷积，5*5卷积，7*7卷积，identity，3*3的均值池化，3*3的最大值池化，3*3的加宽池化，1*7后接7*1的卷积。
组合操作C使用按位加和的操作。
第b个块表示为Bb，大小为|Bb|=|Ib|2*|O|2*|C|，|Ib|=（2+b-1），|O|=8，|C|=1。如果每个cell中达到B=5个块，cell的搜索空间将非常大，我们需要更有效的优化方法。

从cell到CNN：为评估cell，要将cell转化为CNN。


方法：
      渐进式神经网络架构搜索
       很多之前的方法都是直接搜索整个cell甚至整个CNN，但这在很大的搜索空间中难以实现。因此我们提出以渐进式的顺序搜索空间。首先，从B1构建所有可能的cell结构并加入队列；训练、评估队列中的模型，通过添加来自B2的所有可能的块结构扩展模型，这样就在第二层获得|B1|*|B2|=256*576=147456个候选cell；使用预测器评估所有候选cell，挑选前K个加入队列，重复这个过程，直到每个cell中有B个块。
      用代理模型预测性能
      对该预测器的要求:（1）能处理任意长度输入串；（2）预测结果接近真实性能；（3）尽可能使用更少的样本。
使用LSTM作为准确率预测器，因为在不同的block中可以使用同一个预测器。

实验：
在搜索过程中，使用CIFAR-10，图片较小；每个子网络训练20轮；K为256，N为2，F为24。
搜索之后，使用CIFAR-10或ImageNet，每个子网络训练更多轮次，设置更大的N和F。

解决问题的核心：将cell从简单到复杂推进，加快好的CNN结构的搜索，并结合预测器的使用。该模型达到同之前一样的性能但使用更少的计算资源。





